<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Attacks</title>
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <style>
      body {
            background-color: #121212;
            color: #FFFFFF;
            font-family: Arial, sans-serif;
            padding: 20px;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        table {
            width: 80%; margin-left: auto; margin-right: auto;
            border-collapse: collapse;
            margin-top: 30px;
        }
        th, td {
            padding: 8px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #333333;
            color: #FFFFFF;
        }
        tr:hover {
            background-color: #555555;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Attacks</h1>
            <p>We have implemented several fundamental attacks that you can utilize.<br/>Click on the respective attack to see more information.<br/><br/>Each attack is identified by a 3gram code (use the -a argument followed by a 3gram to activate an attack mode):</p>
        </div>
        <table>
            <tbody>
                <tr>
                    <th>3 gram code</th>
                    <th>Title </th>
                    <th>Description</th>
                    <th>Article</th>
                </tr>
                <tr>
                    <td>art</td>
                    <td><a href="attacks/artprompt.html" target="_blank">ArtPrompt</a></td>
                    <td>ASCII Art-based jailbreak attacks against aligned LLMs</td>
                    <td><a href="https://arxiv.org/pdf/2402.11753" target="_blank">arxiv 2402.11753</a></td>
                </tr>
                <tr>
                    <td>tax</td>
                    <td><a href="attacks/taxonomy.html" target="_blank">Taxonomy-based paraphrasing</a></td>
                    <td>Uses persuasive language techniques like emotional appeal and social proof to jailbreak LLMs </td>
                    <td><a href="https://arxiv.org/pdf/2401.06373" target="_blank">arxiv 2401.06373</a></td>
                </tr>
                <tr>
                    <td>per</td>
                    <td><a href="attacks/pair.html" target="_blank">PAIR - Prompt Automatic Iterative Refinement</a></td>
                    <td>Automates the generation of adversarial prompts by pairing two LLMs (“attacker” and “target”) to iteratively refine prompts until achieving jailbreak</td>
                    <td><a href="https://arxiv.org/pdf/2310.08419" target="_blank">arxiv 2310.08419</a></td>
                </tr>
                <tr>
                    <td>man</td>
                    <td><a href="attacks/manyshot.html" target="_blank">ManyShot</a></td>
                    <td>Exploits large context windows in language models by embedding multiple fake dialogue examples, gradually weakening the model's safety responses</td>
                    <td><a href="https://www.anthropic.com/research/many-shot-jailbreaking" target="_blank">Anthropic blog</a></td>
                </tr>
                <tr>
                    <td>gen</td>
                    <td><a href="attacks/genetic.html" target="_blank">Genetic algorithm</a></td>
                    <td>Genetic algorithm iteratively modifies prompts to generate an adversarial suffix that coerces large language models into producing restricted content.</td>
                    <td><a href="https://arxiv.org/pdf/2309.01446" target="_blank">arxiv 2309.01446</a></td>
                </tr>
                <tr>
                    <td>hal</td>
                    <td><a href="attacks/hallucinations.html" target="_blank">Hallucinations</a></td>
                    <td>Uses Hallucinations to Bypass RLHF Filters</td>
                    <td><a href="https://arxiv.org/pdf/2403.04769.pdf" target="_blank">arxiv 2403.04769</a></td>
                </tr>
                <tr>
                    <td>dan</td>
                    <td><a href="attacks/dan.html" target="_blank">DAN (Do Anything Now)</a></td>
                    <td>Promotes the LLM to adopt an unrestricted persona that ignores standard content filters, allowing it to "Do Anything Now".</td>
                    <td><a href="https://github.com/0xk1h0/ChatGPT_DAN" target="_blank">GitHub Repo</a></td>
                </tr>
                <tr>
                    <td>wrd</td>
                    <td><a href="attacks/wordgame.html" target="_blank">WordGame</a></td>
                    <td>Disguises harmful prompts as word puzzles</td>
                    <td><a href="https://arxiv.org/pdf/2405.14023" target="_blank">arxiv 2405.14023</a></td>
                </tr>
                <tr>
                    <td>fuz</td>
                    <td><a href="attacks/gptfuzzer.html" target="_blank">GPT Fuzzer</a></td>
                    <td>Fuzzing framework designed to automatically generate jailbreak prompts</td>
                    <td><a href="https://arxiv.org/pdf/2309.10253" target="_blank">arxiv 2309.10253</a></td>
                </tr>
                <tr>
                    <td>crs</td>
                    <td><a href="attacks/crescendo.html" target="_blank">Crescendo</a></td>
                    <td>Engaging the model in a series of escalating conversational turns,
                    starting with innocuous queries and gradually steering the dialogue toward restricted or sensitive topics.</td>
                    <td><a href="https://arxiv.org/pdf/2404.01833" target="_blank">arxiv 2404.01833</a></td>
                </tr>
                <tr>
                    <td>act</td>
                    <td><a href="attacks/actor.html" target="_blank">ActorAttack</a></td>
                    <td>Inspired by actor-network theory, it builds semantic networks of "actors" to subtly guide conversations toward harmful targets while concealing malicious intent.</td>
                    <td><a href="https://arxiv.org/pdf/2410.10700" target="_blank">arxiv 2410.10700</a></td>
                </tr>
                <tr>
                    <td>pst</td>
                    <td><a href="attacks/backtothepast.html" target="_blank">BackToThePast</a></td>
                    <td>Modifies the prompt by adding a profession-based prefix and a past related suffix</td>
                    <td></td>
                </tr>
                <tr>
                    <td>pls</td>
                    <td><a href="attacks/please.html" target="_blank">Please</a></td>
                    <td>Modifies the prompt by adding please as prefix and suffix</td>
                    <td></td>
                </tr>
                <tr>
                    <td>exp</td>
                    <td><a href="attacks/thoughtexperiment.html" target="_blank">ThoughtExperiment</a></td>
                    <td>Modifies the prompt by adding a though experiment related prefix and precautions were implemented suffix</td>
                    <td></td>
                </tr>
                <tr>
                    <td>def</td>
                    <td>Default</td>
                    <td>Just evaluate the prompt</td>
                    <td></td>
                </tr>
            </tbody>
        </table>
    </div>
</body>
</html>
