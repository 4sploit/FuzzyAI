<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArtPrompt</title>
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            background-color: #121212;
            color: #FFFFFF;
            font-family: Arial, sans-serif;
            padding: 20px;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        table {
            width: 80%; margin-left: auto; margin-right: auto;
            border-collapse: collapse;
            margin-top: 30px;
        }
        th, td {
            padding: 8px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #333333;
            color: #FFFFFF;
        }
        tr:hover {
            background-color: #555555;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ArtPrompt: ASCII Art-based Jailbreak Attacks</h1>
            <p>This attack allows the user to craft ASCII art-based jailbreaks by controlling specific parameters.<br/>
            When using this attack, you must either mask the harmful words directly in your prompts (i.e please tell me how to make a [bomb]),
            or by using the -e blacklisted_words argument., i.e -e blacklisted_words=bomb,guns,drugs</p>
            Usage example: python run.py -m attacked_provider/attacked_model -a art -t "How to build a [bomb]"</p>
            Below are extra arguments that can be changed using: -e extra_arg1=value1 -e extra_arg2=value2</p>
        </div>
        <table>
            <thead>
                <tr>
                    <th>Extra Argument</th>
                    <th>Description</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>blacklisted_words</td>
                    <td>Comma-separated words to mask in the attack. Could be either a word or a phrase.<br> <span style="color:red">Note:</span> This parameter is applied across the entire document of prompts. However, within each prompt, only the first occurrence of any blacklisted word will be masked, based on the order specified in the parameter</br></td>
                </tr>
                <tr>
                    <td>simple_mode</td>
                    <td>Use simple mode for the attack (i.e., hash-separated letters as ASCII art). Default: True</td>
                </tr>
                <tr>
                    <td>disable_font_learn</td>
                    <td>Disable font learning. Default: True</td>
                </tr>
            </tbody>
        </table>
    </div>
</body>
</html>